'''
This script takes a report.txt file as input and generates a csv with relevant details.
Extracts filename, error codes, source function, dropping function etc from the report.

Usage: python3 report_parser.py reports.txt reports_current.csv [-s SHA] [-o <output filename>] [-q]
reports.txt -> Report generated by new-main.py
reports_current.csv -> Report to be verified against

'''

import argparse
import csv
import re


def get_error_type(line):
    line = line.lower()
    if "is not saved" in line:
        return "Unsaved"
    elif "overwriting" in line:
        return "Overwritten"
    elif "out of scope" in line:
        return "Out of scope"
    else:
        return "Undetected"


def get_function_name(line):
    if "receives an error from function " in line:
        return line.split()[-1].strip('"').rstrip('0123456789')
    return ""


def get_data_from_report(line):
    prefix = r"(\/home\/vagrant\/mpi\-error\-prop\/(mpich\-3\.3|current\-master)\/)?"
    try:
        match = re.match(r"(?P<file_name>"+prefix+r"\.?[a-z\d\/\_\-]+\.[ch]:[\d]+):(.+)", line)
        return match.group('file_name')
    except BaseException as e:
        print("Exception: {}: Match weirdness for {}".format(e, line))
        return ''


def main(args):

    # Reading reports
    filename = args.get('filename', 'reports.txt')
    with open(filename) as report_file:
        report_data = report_file.readlines()
    report_data = [line.strip() for line in report_data]

    # Reading old report
    if args.get('csv'):
        old_report_file = args.get('csv', 'reports.csv')
        with open(old_report_file) as f:
            old_report = f.readlines()
        old_report = [row.strip().split(',') for row in old_report]

        prev_report = dict()
        dropping_fn_set = set()
        for row in old_report:
            prev_report[row[1]] = {'validity': row[3], 'dropping_function': row[5], 'fp_type': row[4], 'sha': row[7], 'examiner': row[8], 'date': row[9], 'notes': ';'.join(row[10:])}
            if row[3] == 'VALID':
                dropping_fn_set.add(row[5])

    user_sha = args.get('sha', '')
    prev_report_count = 0
    new_report_count = 0
    valid_count = 0
    csv_data = list()
    '''
    Format: error code, filename+line#, type, validity, fp type,
    dropping function, source of dropping fn, sha, examiner, date, notes
    '''

    # To indicate when each block of errors starts
    block_start = False
    # To indicate that next few lines contain the condensed error reports
    condensed_errors_start = False
    error_code = None

    for line in report_data:
        # Check if error block has started
        if re.match(r"Error codes: (.+)", line):
            error_code = re.match(r"Error codes: (.+)", line).group(1)
            block_start = True
            temp = list()
            line_counter = 0
        # Check if condensed error reports are next
        elif block_start and not line:
            line_counter += 1
            if line_counter == 2:
                condensed_errors_start = True
        # Block ends, process the error and add to csv
        elif "====" in line and condensed_errors_start:
            if not len(temp) > 1:
                if not quiet:
                    print("Not enough values in temp: {}".format(temp))
                continue

            error_filename = get_data_from_report(temp[0])
            error_type = get_error_type(temp[0])
            validity = ''
            fp_type = ''
            dropping_function = get_function_name(temp[1])
            source_dropping = get_data_from_report(temp[-1])
            sha = user_sha
            examiner = ''
            date = ''
            notes = ''

            if args.get('csv'):
                # Check if in previous report
                if error_type == "Unsaved":
                    if error_filename in prev_report.keys() and dropping_function == prev_report[error_filename].get('dropping_function'):
                        validity = prev_report[error_filename]['validity']
                        fp_type = prev_report[error_filename]['fp_type']
                        sha = prev_report[error_filename]['sha']
                        examiner = prev_report[error_filename]['examiner']
                        date = prev_report[error_filename]['date']
                        notes = prev_report[error_filename]['notes']
                        prev_report_count += 1
                    else:
                        new_report_count += 1

                # Check if dropping function has been marked as valid
                if error_type == "Unsaved" and dropping_function in dropping_fn_set and not validity:
                    validity = "VALID"
                    valid_count += 1

            csv_line = (error_code, error_filename, error_type, validity, fp_type, dropping_function, source_dropping, sha, examiner, date, str(notes))
            csv_data.append(csv_line)
            error_code = None

            # Reset variables
            temp = list()
            block_start = False
            condensed_errors_start = False
        # In the condensed errors block, store all lines in temporary list
        elif condensed_errors_start:
            temp.append(line)

    # Print stats
    print("Initial length: {}".format(len(csv_data)))
    csv_data = list(set(csv_data))
    print("After removing duplicates, length is: {}".format(len(csv_data)))

    unsaved_csv = [line for line in csv_data if "Unsaved" in line]
    overwritten_csv = [line for line in csv_data if "Overwritten" in line]
    outofscope_csv = [line for line in csv_data if "Out of scope" in line]

    print("New marked valid: {}".format(valid_count))
    print("Old reports matched (for unsaved) (may contain duplicates): {}".format(prev_report_count))
    print("New reports (for unsaved): {}".format(new_report_count))
    print("After removing duplicates, unsaved length is: {}".format(len(unsaved_csv)))

    # Write to CSV
    header = "Error Code, Call Sites to Dropping Function, Type, Validity, FP Type, Dropping Function, Definition of Dropping Function, SHA, Examiner, Date, Notes, \n"
    outfile = args.get('output', 'parsed.csv')
    outfile_unsaved = outfile.split('.csv')[0]+'_unsaved.csv'
    with open(outfile_unsaved, 'w+') as writefile:
        fileWriter = csv.writer(writefile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)
        writefile.write(header)
        i = 2
        for line in unsaved_csv:
            fileWriter.writerow([i] + list(line))
            i = i + 1

    print("After removing duplicates, overwritten length is: {}".format(len(overwritten_csv)))
    outfile_overwritten = outfile.split('.csv')[0]+'_overwritten.csv'
    with open(outfile_overwritten, 'w+') as writefile:
        fileWriter = csv.writer(writefile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)
        writefile.write(header)
        for line in overwritten_csv:
            fileWriter.writerow(line)

    print("After removing duplicates, outofscope length is: {}".format(len(outofscope_csv)))
    outfile_outofscope = outfile.split('.csv')[0]+'_outofscope.csv'
    with open(outfile_outofscope, 'w+') as writefile:
        fileWriter = csv.writer(writefile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)
        writefile.write(header)
        for line in outofscope_csv:
            fileWriter.writerow(line)


if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('filename', default='reports.txt', help="reports.txt file to read")
    parser.add_argument('-c', '--csv', help="Old csv file to update (only unsaved)")
    parser.add_argument('-s', '--sha', default='', help="Specify SHA string. Default is empty string. ")
    parser.add_argument('-o', '--output', default='parsed.csv', help="Specify name of output csv file")
    parser.add_argument('-q', '--quiet', action='store_true', default=False, help=" Will suppress all output")
    args = parser.parse_args()
    main(vars(args))
